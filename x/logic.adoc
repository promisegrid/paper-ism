[[1]] 1. If we assume that all computable results have already been computed, then the outputs of any computation are readily available. Our primary task becomes understanding how to index and access these precomputed results.

[[2]] 2. Since all functions are already computed in this scenario, invoking a function equates to performing a lookup in a table of results. This table can be indexed by the function identifier and its input values, simplifying function calls to retrieval operations.

[[3]] 3. We can use very large hashes as pointers to represent the function's algorithm and its input values. These hashes serve as unique identifiers that allow us to efficiently reference and access the associated data.

[[4]] 4. If function calls are lookups, then the lookup table effectively becomes a list of assertions about functions, their inputs, and their outputs. Each entry asserts that a particular input to a function yields a specific output.

[[5]] 5. For a given function call and input value set, there may exist multiple competing assertions. Our challenge is to determine which assertion is most likely to be correct, necessitating a method to evaluate their validity.

[[6]] 6. We can employ Promise Theory to track the assertions made by agents who contribute to the lookup table. If an agent's assertion consistently holds true over time, we can consider that agent to be more trustworthy.

[[7]] 7. Given that we are assuming all functions are precomputed and function calls are lookups, we can extend this concept to include all data—including function call algorithms—as entries indexed in the table.

[[8]] 8. By using hashes as pointers to algorithms or data items, retrieving data becomes a matter of looking up the hash in the table index and following the pointer to the actual data. This simplifies data retrieval to a standardized lookup process.

[[9]] 9. Similarly, storing data involves placing the data at the location specified by its hash in the table index. This method ensures that data is stored and can be retrieved based on its content-derived hash value.

[[10]] 10. Since all data is indexed in the table, we can chain the output data from one function call to the input data of another. This allows for the seamless composition of functions and data flows.

[[11]] 11. By chaining all function calls and data, we can construct a hypergraph that represents all function calls and data within the system. This hypergraph encapsulates the relationships and dependencies among computational elements.

[[12]] 12. Building on <<11>>, we can extend the hypergraph to include all agents in the system and their interactions. This expanded hypergraph models not just computational processes but also the agents involved and their relationships.

[[13]] 13. Utilizing Promise Theory to track assertions and outcomes within this hypergraph, we can more effectively determine which agents to trust. By evaluating the cumulative outcomes of agents' assertions in specific branches of the hypergraph, we can make informed trust decisions.

[[14]] 14. As a result of <<13>>, we can develop a decentralized system that is more resilient to attacks and scales better than centralized systems. The decentralized nature reduces single points of failure and distributes trust across multiple agents.

[[15]] 15. Ultimately, by constructing a decentralized, resilient, and scalable system as described in <<14>>, we can achieve a system that is more equitable and accurate in its decision-making processes compared to traditional centralized systems.
